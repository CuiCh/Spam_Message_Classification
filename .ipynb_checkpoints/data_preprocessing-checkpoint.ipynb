{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from scipy import io\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(rawdata,n):\n",
    "    \"\"\"\n",
    "    Purpose:加载原始数据，处理并输出\n",
    "    \n",
    "    \"\"\"\n",
    "    alldata = pd.read_csv(rawdata,header=None)\n",
    "    alldata.columns = [\"label\",\"content\"]\n",
    "    data = alldata.sample(n)\n",
    "    content = data[\"content\"]\n",
    "    label=data[\"label\"]\n",
    "    return content,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_path = \"rawdata/traindata.csv\"\n",
    "content ,label = load_data(rawdata_path,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageCountVectorizer(sklearn.feature_extraction.text.CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        def analyzer(doc):\n",
    "            words = jieba.cut(doc)\n",
    "            return words\n",
    "        return analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_data(content,label):\n",
    "    \"\"\"\n",
    "    函数说明：得到每个短信的内容和标签的向量表示\n",
    "    Return:\n",
    "        vect_result - 短信的向量表示\n",
    "    Modify:\n",
    "        2017-12-22\n",
    "    \n",
    "    \"\"\"\n",
    "    vect = \tMessageCountVectorizer(max_df=0.9,min_df=2)\n",
    "    vect_result=vect.fit_transform(content)\n",
    "\n",
    "    words = vect.get_feature_names()\n",
    "    io.mmwrite(\"data/content_vector.mtx\",vect_result)\n",
    "    print(label)\n",
    "    io.mmwrite(\"data/label_vector\",label)\n",
    "    print(words)\n",
    "    print(len(words))\n",
    "    print(vect_result.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597363    1\n",
      "389380    0\n",
      "644816    0\n",
      "220541    0\n",
      "213792    0\n",
      "669048    0\n",
      "348089    1\n",
      "223072    0\n",
      "609600    0\n",
      "728001    0\n",
      "76693     0\n",
      "782039    0\n",
      "437495    0\n",
      "173458    0\n",
      "433323    0\n",
      "679704    0\n",
      "656113    0\n",
      "477913    1\n",
      "507999    0\n",
      "325064    0\n",
      "765361    1\n",
      "771041    0\n",
      "501300    0\n",
      "31986     0\n",
      "70581     1\n",
      "556656    0\n",
      "179101    0\n",
      "240064    0\n",
      "253517    0\n",
      "794936    0\n",
      "         ..\n",
      "298879    0\n",
      "615504    0\n",
      "198046    0\n",
      "576436    0\n",
      "470677    0\n",
      "625754    0\n",
      "297488    0\n",
      "297477    0\n",
      "29789     0\n",
      "598238    0\n",
      "713878    0\n",
      "421113    0\n",
      "81207     0\n",
      "720113    0\n",
      "319801    0\n",
      "4185      0\n",
      "312801    0\n",
      "438160    0\n",
      "302887    0\n",
      "616915    0\n",
      "86411     0\n",
      "608579    0\n",
      "433299    0\n",
      "404771    0\n",
      "642562    0\n",
      "285661    0\n",
      "610332    0\n",
      "360420    0\n",
      "449980    0\n",
      "303384    0\n",
      "Name: label, Length: 100, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2 dimensional array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-d5fcac1fa5e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvect_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-76-cef8eb7c2e43>\u001b[0m in \u001b[0;36mvect_data\u001b[1;34m(content, label)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/content_vector.mtx\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvect_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/label_vector\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36mmmwrite\u001b[1;34m(target, a, comment, field, precision, symmetry)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m     \u001b[0mMMFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymmetry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, target, a, comment, field, precision, symmetry)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymmetry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Anaconda3\\lib\\site-packages\\scipy\\io\\mmio.py\u001b[0m in \u001b[0;36m_write\u001b[1;34m(self, stream, a, comment, field, precision, symmetry)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected 2 dimensional array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m             \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2 dimensional array"
     ]
    }
   ],
   "source": [
    "vect_data(content,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'为了', '互联网', '扩展', '数字', '服务', '汽车', '的'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(jieba.cut(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type 'ndarray' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-2f7063cb3496>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# io.mmwrite(\"data/label_vector\",label.as_matrix())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/label_vector.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Developer\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    435\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Developer\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[1;32m--> 180\u001b[1;33m                         o.__class__.__name__)\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type 'ndarray' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# io.mmwrite(\"data/label_vector\",label.as_matrix())\n",
    "with open('data/label_vector.json', 'w') as f:\n",
    "        json.dump(label.as_matrix(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'为了', '互联网', '扩展', '数字', '服务', '汽车'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(jieba.cut(s)) - stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=(pseg.cut(s))\n",
    "# new_doc=''.join(w.word for w in words if w.flag != 'x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'为了扩展互联网汽车的数字服务'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng nihaom\n",
      "x  \n",
      "eng xxxx\n",
      "x  \n",
      "l 你好\n",
      "y 吗\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s= \"nihaom xxxx 你好吗\"\n",
    "words=(pseg.cut(s))\n",
    "for w in words:\n",
    "    print(w.flag,w.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"data/traindata.csv\"\n",
    "# 加载全部数据\n",
    "alldata = pd.read_csv(filepath,header=None)\n",
    "alldata.columns=[\"label\",\"content\"]\n",
    "alldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 随机抽取n条数据\n",
    "data = alldata.sample(n=1000)\n",
    "# data = alldata.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    902\n",
       "1     98\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logtime(func):\n",
    "    \"\"\"\n",
    "    函数目的：测量函数运行时间\n",
    "    Parameter:\n",
    "        func - 被测量的函数\n",
    "    Return:\n",
    "        wrapper - 被装饰之后的函数\n",
    "    \"\"\"\n",
    "    def wrapper(*args,**kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args,**kwargs)\n",
    "        end = time.time()\n",
    "        print(\"完成函数{name}, 运行时间 {totaltime:.3f}s\".format(name=func.__name__,totaltime=end-start))\n",
    "        start = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(start))\n",
    "        end = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(end))\n",
    "        print(\"开始时间 : %s \\n结束时间 : %s \"%(start,end))\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@logtime\n",
    "def loadStopWords(filepath):\n",
    "    \"\"\"\n",
    "    函数说明：加载获取停用词列表\n",
    "    Parameter:\n",
    "        filepath - 停用词文件的路径\n",
    "    Return:\n",
    "        stopwords - 以集合形式返回的停用词列表\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    stopwordfile = open(filepath,\"r\",encoding=\"utf-8\").readlines()\n",
    "    stopwords = {line.strip() for line in stopwordfile}\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成函数loadStopWords, 运行时间 0.000s\n",
      "开始时间 : 2017-12-04 22:14:11 \n",
      "结束时间 : 2017-12-04 22:14:11 \n"
     ]
    }
   ],
   "source": [
    "stopwordsfile = \"data/stopwords.txt\"\n",
    "stopwords = loadStopWords(stopwordsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@logtime\n",
    "def getVocalist(contents,stopwords):\n",
    "    \"\"\"\n",
    "    函数说明：获取去除停用词后的词汇表，来减小向量维度的大小\n",
    "    Parameter:\n",
    "        data - 待处理的文本数据\n",
    "        stopwords - 停用词列表\n",
    "    Return:\n",
    "        list(vocalist)- 文本词汇表\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    vocalist = set([])\n",
    "    for i in range(len(data)):\n",
    "        content = contents.iloc[i]\n",
    "        segresult = set(jieba.cut(content))\n",
    "        # 两个集合求并集\n",
    "        vocalist = vocalist | segresult\n",
    "    vocalist = vocalist - stopwords\n",
    "    # print(vocalist)\n",
    "    print(\"词汇表长度为：\",len(vocalist))\n",
    "    return list(vocalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\CC\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.825 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表长度为： 5778\n",
      "完成函数getVocalist, 运行时间 1.121s\n",
      "开始时间 : 2017-12-04 22:14:17 \n",
      "结束时间 : 2017-12-04 22:14:18 \n"
     ]
    }
   ],
   "source": [
    "contents = data[\"content\"]\n",
    "vocalist=getVocalist(contents,stopwords)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 文本信息矢量化\n",
    "def Vectorization(content,vocalist,stopwords):\n",
    "    \"\"\"\n",
    "    函数说明：得到每个短信的0-1向量表示，如[0,0,0,1,0,1,0,0,0,0....]，向量长度与词汇表长度相同\n",
    "    Paremeter:\n",
    "        content -  每条短信的内容\n",
    "        vocalist - 词汇表\n",
    "        stopwords - 停用词列表\n",
    "    Return:\n",
    "        vector - 每条短信的向量表示\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    vector= [0]*len(vocalist)\n",
    "    segresult = set(jieba.cut(content))-stopwords\n",
    "    for word in segresult:\n",
    "        vector[vocalist.index(word)] = 1\n",
    "    return vector\n",
    "@logtime\n",
    "def vectall(data,vocalist,stopwords):\n",
    "    data[\"vector\"] = data.apply(lambda row:Vectorization(row[\"content\"],vocalist,stopwords),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成函数vectall, 运行时间 0.912s\n",
      "开始时间 : 2017-12-04 22:14:46 \n",
      "结束时间 : 2017-12-04 22:14:47 \n"
     ]
    }
   ],
   "source": [
    "# 得到每个文本的矢量化结果\n",
    "vectall(data,vocalist,stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 随机划分训练数据和测试数据 8:2\n",
    "traindata,testdata = train_test_split(data,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据的标签分布：\n",
      "0    721\n",
      "1     79\n",
      "Name: label, dtype: int64\n",
      "测试数据的标签分布：\n",
      "0    181\n",
      "1     19\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据的标签分布：\")\n",
    "print(traindata[\"label\"].value_counts())\n",
    "print(\"测试数据的标签分布：\")\n",
    "print(testdata[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建分类器\n",
    "@logtime\n",
    "def trainclassifier(traindata):\n",
    "    \"\"\"\n",
    "    函数说明：构建不同种类的分类器\n",
    "    Parameter:\n",
    "        traindata - 训练数据\n",
    "    Return:\n",
    "        classifier.fit(vector,label) - 训练好的分类器\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    classifier = svm.SVC(C=50,kernel='linear')\n",
    "    # 需转换为list,不然报错\n",
    "    vector = list(traindata[\"vector\"])\n",
    "    label = list(traindata[\"label\"])\n",
    "    return classifier.fit(vector,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成函数trainclassifier, 运行时间 5.286s\n",
      "开始时间 : 2017-12-04 22:14:57 \n",
      "结束时间 : 2017-12-04 22:15:02 \n"
     ]
    }
   ],
   "source": [
    "classificer = trainclassifier(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成函数applyClassificer, 运行时间 1.009s\n",
      "开始时间 : 2017-12-04 22:15:05 \n",
      "结束时间 : 2017-12-04 22:15:06 \n"
     ]
    }
   ],
   "source": [
    "# 应用分类器\n",
    "@logtime\n",
    "def applyClassificer(classificer,testdata):\n",
    "    return classificer.predict(list(testdata[\"vector\"]))\n",
    "pred = applyClassificer(classificer,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elevate_result(label,pred):\n",
    "    \"\"\"\n",
    "    函数说明: 对分类器预测的结果进行评估，包括accurancy,precision,recall,F-score\n",
    "    Parameter:\n",
    "        label - 真实值\n",
    "        pred - 预测值\n",
    "    Return:\n",
    "        None\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    con_mat = metrics.confusion_matrix(label,pred)\n",
    "    TP = con_mat[1,1]\n",
    "    TN = con_mat[0,0]\n",
    "    FP = con_mat[0,1]\n",
    "    FN = con_mat[1,0]\n",
    "    \n",
    "    accurancy = (TP+TN)/(TP+TN+FN+FP)\n",
    "    precison = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    beta = 1\n",
    "    F_score = (1+pow(beta,2))*precison*recall/(pow(beta,2)*precison+recall)\n",
    "    \n",
    "    print(\"TP:\",TP)\n",
    "    print(\"TN:\",TN)\n",
    "    print(\"FP:\",FP)\n",
    "    print(\"FN:\",FN)\n",
    "    print(\"accurancy: %s \\nprecison: %s \\nrecall: %s \\nF-score: %s\" % (accurancy,precison,recall,F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 16\n",
      "TN: 181\n",
      "FP: 0\n",
      "FN: 3\n",
      "accurancy: 0.985 \n",
      "precison: 1.0 \n",
      "recall: 0.842105263158 \n",
      "F-score: 0.914285714286\n"
     ]
    }
   ],
   "source": [
    "label = testdata[\"label\"]\n",
    "elevate_result(label,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
