{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"data/traindata.csv\"\n",
    "# 加载全部数据\n",
    "alldata = pd.read_csv(filepath,header=None)\n",
    "alldata.columns=[\"label\",\"content\"]\n",
    "alldata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 随机抽取n条数据\n",
    "# data = alldata.sample(n=500)\n",
    "data = alldata.iloc[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    451\n",
       "1     49\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStopWords(filepath):\n",
    "    \"\"\"\n",
    "    函数说明：获取停用词，包括数字，标点符号，常见的中文词汇“的、地、得”等\n",
    "    Parameter:\n",
    "        filepath - 停用词文件的路径\n",
    "    Return:\n",
    "        stopwords - 以集合形式返回的停用词列表\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    stopwordfile = open(filepath,\"r\",encoding=\"utf-8\").readlines()\n",
    "    stopwords = {line.strip() for line in stopwordfile}\n",
    "#     stopwords = set()\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsfile = \"data/stopwords.txt\"\n",
    "stopwords = getStopWords(stopwordsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getVocalist(contents,stopwords):\n",
    "    \"\"\"\n",
    "    函数说明：获取去除停用词后的词汇表，来减小向量维度的大小\n",
    "    Parameter:\n",
    "        data - 待处理的文本数据\n",
    "        stopwords - 停用词列表\n",
    "    Return:\n",
    "        list(vocalist)- 文本词汇表\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    vocalist = set([])\n",
    "    for i in range(len(data)):\n",
    "        content = contents.iloc[i]\n",
    "        segresult = set(jieba.cut(content))\n",
    "        # 两个集合求并集\n",
    "        vocalist = vocalist | segresult\n",
    "    vocalist = vocalist - stopwords\n",
    "    # print(vocalist)\n",
    "    print(\"词汇表长度为：\",len(vocalist))\n",
    "    return list(vocalist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表长度为： 3296\n"
     ]
    }
   ],
   "source": [
    "contents = data[\"content\"]\n",
    "vocalist=getVocalist(contents,stopwords)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 文本信息矢量化\n",
    "def getVect(content,vocalist,stopwords):\n",
    "    \"\"\"\n",
    "    函数说明：得到每个短信的0-1向量表示，如[0,0,0,1,0,1,0,0,0,0....]，向量长度与词汇表长度相同\n",
    "    Paremeter:\n",
    "        content -  每条短信的内容\n",
    "        vocalist - 词汇表\n",
    "        stopwords - 停用词列表\n",
    "    Return:\n",
    "        vector - 每条短信的向量表示\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    vector= [0]*len(vocalist)\n",
    "    segresult = set(jieba.cut(content))-stopwords\n",
    "    for word in segresult:\n",
    "        vector[vocalist.index(word)] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Developer\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 得到每个文本的矢量化结果\n",
    "data[\"vector\"] = data.apply(lambda row:getVect(row[\"content\"],vocalist,stopwords),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机划分训练数据和测试数据 8:2\n",
    "# traindata,testdata = train_test_split(data,test_size=0.2)\n",
    "traindata = data.iloc[:int(0.8*len(data))]\n",
    "testdata = data.iloc[int(0.8*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据的标签分布：\n",
      "0    357\n",
      "1     43\n",
      "Name: label, dtype: int64\n",
      "测试数据的标签分布：\n",
      "0    94\n",
      "1     6\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据的标签分布：\")\n",
    "print(traindata[\"label\"].value_counts())\n",
    "print(\"测试数据的标签分布：\")\n",
    "print(testdata[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建分类器\n",
    "def trainclassifier(traindata):\n",
    "    \"\"\"\n",
    "    函数说明：构建不同种类的分类器\n",
    "    Parameter:\n",
    "        traindata - 训练数据\n",
    "    Return:\n",
    "        classifier.fit(vector,label) - 训练好的分类器\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    classifier = svm.SVC(C=50,kernel='linear')\n",
    "    # 需转换为list,不然报错\n",
    "    vector = list(traindata[\"vector\"])\n",
    "    label = list(traindata[\"label\"])\n",
    "    return classifier.fit(vector,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classificer = trainclassifier(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 应用分类器\n",
    "pred = classificer.predict(list(testdata[\"vector\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elevate_result(label,pred):\n",
    "    \"\"\"\n",
    "    函数说明: 对分类器预测的结果进行评估，包括accurancy,precision,recall,F-score\n",
    "    Parameter:\n",
    "        label - 真实值\n",
    "        pred - 预测值\n",
    "    Return:\n",
    "        None\n",
    "    Modify:\n",
    "        2017-12-02\n",
    "    \"\"\"\n",
    "    con_mat = metrics.confusion_matrix(label,pred)\n",
    "    TP = con_mat[1,1]\n",
    "    TN = con_mat[0,0]\n",
    "    FP = con_mat[0,1]\n",
    "    FN = con_mat[1,0]\n",
    "    \n",
    "    accurancy = (TP+TN)/(TP+TN+FN+FP)\n",
    "    precison = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    beta = 1\n",
    "    F_score = (1+pow(beta,2))*precison*recall/(pow(beta,2)*precison+recall)\n",
    "    \n",
    "    print(\"TP:\",TP)\n",
    "    print(\"TN:\",TN)\n",
    "    print(\"FP:\",FP)\n",
    "    print(\"FN:\",FN)\n",
    "    print(\"accurancy: %s \\nprecison: %s \\nrecall: %s \\nF-score: %s\" % (accurancy,precison,recall,F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 5\n",
      "TN: 94\n",
      "FP: 0\n",
      "FN: 1\n",
      "accurancy: 0.99 \n",
      "precison: 1.0 \n",
      "recall: 0.833333333333 \n",
      "F-score: 0.909090909091\n"
     ]
    }
   ],
   "source": [
    "label = testdata[\"label\"]\n",
    "elevate_result(label,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getstopwordlist = \"data/data50.txt\"\n",
    "partdata = pd.read_csv(getstopwordlist,header=None)\n",
    "partdata.columns=[\"label\",\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = partdata[\"content\"]\n",
    "stop={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-356-11736874b6c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mstop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "for i in range(len(contents)):\n",
    "    content = contents.iloc[i]\n",
    "    segresult = list(jieba.cut(content))\n",
    "    for seg in segresult:\n",
    "        if seg in stop.keys():\n",
    "            stop[seg]+=1\n",
    "        else:\n",
    "            stop[seg]=1\n",
    "stop = sorted(stop.iteritems(),key=lambda item:item[1],reverse = True)\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
